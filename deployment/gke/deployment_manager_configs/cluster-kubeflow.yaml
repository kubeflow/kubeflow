# Copyright 2016 Google Inc. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

imports:
- path: cluster.jinja

resources:
  # Deployment manager doesn't support depends on references in template type.
  # So the two possible work arounds are
  # 1. Use a single template (.jinja file for all resources) or
  # 2. Create two separate deployments and launch the boot strapper
  # after the cluster is created.
  #
  # Two separate deployments doesn't make much sense; we could just use
  # kubectl at that point. So we put all resources in a single deployment.
- name: kubeflow
  type: cluster.jinja
  properties:
    # You need to use a zone with Broadwell because that's what TFServing requires.
    zone: SET_THE_ZONE
    # "1.X": picks the highest valid patch+gke.N patch in the 1.X version
    # https://cloud.google.com/kubernetes-engine/docs/reference/rest/v1/projects.zones.clusters
    cluster-version: "1.12"
    # Set this to v1beta1 to use beta features such as private clusterss
    # and the Kubernetes stackdriver agents.
    gkeApiVersion: SET_GKE_API_VERSION
    # Whether to enable workload identity
    enable-workload-identity: false
    identity-namespace: SET_IDENTITY_NAMESPACE
    # An arbitrary string appending to name of nodepools
    # bump this if you want to modify the node pools.
    # This will cause existing node pools to be deleted and new ones to be created.
    # Use prefix v so it will be treated as a string.
    pool-version: v1
    # CPU Pool Configs
    # Two is small enough to fit within default quota.
    cpu-pool-initialNodeCount: 2
    # machine type for nodes in cpu pool. Available options: https://cloud.google.com/compute/docs/machine-types
    cpu-pool-machine-type: n1-standard-8
    # Autoscaling parameters
    cpu-pool-enable-autoscaling: true
    cpu-pool-min-nodes: 0
    cpu-pool-max-nodes: 10
    # GPU Pool Configs
    gpu-pool-initialNodeCount: 0
    # machine type for nodes in gpu pool. Available options: https://cloud.google.com/compute/docs/machine-types
    gpu-pool-machine-type: n1-standard-8
    # GPUs are not enabled by default. To add GPUs
    # set gpu-pool-max-nodes to a none-zero value.
    gpu-pool-enable-autoscaling: true
    gpu-pool-min-nodes: 0
    gpu-pool-max-nodes: 0
    # Controls gpu number per node, valid input: [1, num_cpu_per_node], for n1-standard-8, num_cpu_per_node = 8
    gpu-number-per-node: 1
    # Check https://cloud.google.com/compute/docs/gpus/ for available GPU models and their regions
    gpu-type: nvidia-tesla-k80
    # Autoprovisioning parameters (only supported in gkeApiVersion v1beta1).
    # This is configured by the gkeApiVersion setting.
    autoprovisioning-config:
      enabled: true
      max-cpu: 20
      max-memory: 200
      max-accelerator:
        - type: nvidia-tesla-k80
          count: 8
    # Whether to enable TPUs
    enable_tpu: false
    securityConfig:
      # Whether to use a cluster with private IPs
      # Use v1beta1 api
      privatecluster: false
      # masterIpv4CidrBlock for private clusters, if enabled
      # Use v1beta1 api
      masterIpv4CidrBlock: 172.16.0.16/28
      # Protect worker node metadata from pods
      # Use v1beta1 api
      secureNodeMetadata: false
      # Whether to enable Pod Security Policy Admission Controller
      # Use v1beta1 api
      podSecurityPolicy: false
      masterAuthorizedNetworksConfigEnabled: false
      masterAuthorizedNetworksConfigCidr:
      - cidrBlock: 1.2.3.4/32
    users:
      # List users to grant appropriate GCP permissions to use Kubeflow.
      # These can either be individual users (Google accounts) or Google
      # Groups.
      # - user:john@acme.com
      # - group:data-scientists@acme.com
    # This is the name of the GCP static ip address reserved for your domain.
    # Each Kubeflow deployment in your project should use one unique ipName among all configs.
    ipName: kubeflow-ip
